{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, LeakyReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy import linalg\n",
    "\n",
    "# Load and preprocess your dataset (images) for training\n",
    "\n",
    "# Define the Generator model\n",
    "def build_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(784, activation='sigmoid'))\n",
    "    model.add(Reshape((28, 28)))\n",
    "    return model\n",
    "\n",
    "# Define the Discriminator model\n",
    "def build_discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=img_shape))\n",
    "    model.add(Dense(128))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Build and compile the GAN model\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential([generator, discriminator])\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "    return model\n",
    "\n",
    "# Training loop\n",
    "def train_gan(generator, discriminator, gan, dataset, latent_dim, epochs, batch_size):\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(dataset.shape[0] // batch_size):\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "            generated_images = generator.predict(noise)\n",
    "            real_images = dataset[np.random.randint(0, dataset.shape[0], batch_size)]\n",
    "\n",
    "            labels_real = np.ones((batch_size, 1))\n",
    "            labels_fake = np.zeros((batch_size, 1))\n",
    "\n",
    "            d_loss_real = discriminator.train_on_batch(real_images, labels_real)\n",
    "            d_loss_fake = discriminator.train_on_batch(generated_images, labels_fake)\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "            labels_gan = np.ones((batch_size, 1))\n",
    "            g_loss = gan.train_on_batch(noise, labels_gan)\n",
    "\n",
    "        print(f'Epoch {epoch}/{epochs} - D Loss Real: {d_loss_real} - D Loss Fake: {d_loss_fake} - G Loss: {g_loss}')\n",
    "\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            save_generated_images(generator, epoch)\n",
    "\n",
    "# MiFID Score Calculation\n",
    "def calculate_mifid_score(real_images, generated_images, num_samples=10000):\n",
    "    def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "        covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "        if not np.isfinite(covmean).all():\n",
    "            msg = f'fid calculation produces singular product; adding {eps} to diagonal of cov estimates'\n",
    "            print(msg)\n",
    "            offset = np.eye(sigma1.shape[0]) * eps\n",
    "            covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "        # Numerical error might give slight imaginary component\n",
    "        if np.iscomplexobj(covmean):\n",
    "            if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "                m = np.max(np.abs(covmean.imag))\n",
    "                raise ValueError(f'Imaginary component {m}')\n",
    "            covmean = covmean.real\n",
    "        tr_covmean = np.trace(covmean)\n",
    "        return np.dot(mu1 - mu2, mu1 - mu2) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean\n",
    "\n",
    "    num_batches = min(len(real_images), len(generated_images)) // num_samples\n",
    "    real_images = real_images[:num_samples * num_batches]\n",
    "    generated_images = generated_images[:num_samples * num_batches]\n",
    "\n",
    "    real_images = real_images.reshape(num_batches, num_samples, -1)\n",
    "    generated_images = generated_images.reshape(num_batches, num_samples, -1)\n",
    "\n",
    "    real_mu = np.mean(real_images, axis=1)\n",
    "    real_sigma = np.cov(real_images, rowvar=False)\n",
    "\n",
    "    fake_mu = np.mean(generated_images, axis=1)\n",
    "    fake_sigma = np.cov(generated_images, rowvar=False)\n",
    "\n",
    "    mifid_score = calculate_frechet_distance(real_mu, real_sigma, fake_mu, fake_sigma)\n",
    "    return mifid_score\n",
    "\n",
    "# Main training and evaluation loop\n",
    "if __name__ == '__main__':\n",
    "    latent_dim = 100\n",
    "    img_shape = (28, 28)\n",
    "    epochs = 10000\n",
    "    batch_size = 128\n",
    "    save_interval = 1000\n",
    "\n",
    "    # Load and preprocess your dataset (images) for training\n",
    "\n",
    "    # Build and compile models\n",
    "    generator = build_generator(latent_dim)\n",
    "    discriminator = build_discriminator(img_shape)\n",
    "    gan = build_gan(generator, discriminator)\n",
    "\n",
    "    # Load and preprocess your dataset (images) for training\n",
    "\n",
    "    # Train the GAN\n",
    "    train_gan(generator, discriminator, gan, dataset, latent_dim, epochs, batch_size)\n",
    "\n",
    "    # Generate a batch of fake images for MiFID calculation\n",
    "    num_samples_for_mifid = 10000\n",
    "    noise_for_mifid = np.random.normal(0, 1, (num_samples_for_mifid, latent_dim))\n",
    "    generated_images_for_mifid = generator.predict(noise_for_mifid)\n",
    "\n",
    "    # Calculate MiFID Score\n",
    "    mifid_score = calculate_mifid_score(real_images, generated_images_for_mifid)\n",
    "    print(f'MiFID Score: {mifid_score}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
